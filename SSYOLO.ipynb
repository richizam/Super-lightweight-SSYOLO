{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70e2dd41-8814-4fc3-882e-18f09be161b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib>=3.2.2\n",
      "  Downloading matplotlib-3.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Collecting numpy<1.24.0,>=1.18.5\n",
      "  Downloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m63.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Collecting opencv-python>=4.1.1\n",
      "  Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (63.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.0/63.0 MB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Requirement already satisfied: Pillow>=7.1.2 in /venv/main/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (11.0.0)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in /venv/main/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in /venv/main/lib/python3.10/site-packages (from -r requirements.txt (line 9)) (2.32.3)\n",
      "Collecting scipy>=1.4.1\n",
      "  Downloading scipy-1.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.6/37.6 MB\u001b[0m \u001b[31m49.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Requirement already satisfied: torch!=1.12.0,>=1.7.0 in /venv/main/lib/python3.10/site-packages (from -r requirements.txt (line 11)) (2.6.0+cu124)\n",
      "Requirement already satisfied: torchvision!=0.13.0,>=0.8.1 in /venv/main/lib/python3.10/site-packages (from -r requirements.txt (line 12)) (0.21.0+cu124)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in /venv/main/lib/python3.10/site-packages (from -r requirements.txt (line 13)) (4.67.1)\n",
      "Collecting protobuf<4.21.3\n",
      "  Downloading protobuf-4.21.2-cp37-abi3-manylinux2014_x86_64.whl (407 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m407.8/407.8 KB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting tensorboard>=2.4.1\n",
      "  Downloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m84.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "Collecting pandas>=1.1.4\n",
      "  Downloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m86.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Collecting seaborn>=0.11.0\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 KB\u001b[0m \u001b[31m72.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: ipython in /venv/main/lib/python3.10/site-packages (from -r requirements.txt (line 34)) (8.34.0)\n",
      "Requirement already satisfied: psutil in /venv/main/lib/python3.10/site-packages (from -r requirements.txt (line 35)) (7.0.0)\n",
      "Collecting thop\n",
      "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.57.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m88.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "Collecting contourpy>=1.0.1\n",
      "  Downloading contourpy-1.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (324 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.0/325.0 KB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting kiwisolver>=1.3.1\n",
      "  Downloading kiwisolver-1.4.8-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m62.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7 in /venv/main/lib/python3.10/site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (2.9.0.post0)\n",
      "Collecting cycler>=0.10\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Collecting pyparsing>=2.3.1\n",
      "  Downloading pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.1/111.1 KB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /venv/main/lib/python3.10/site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (24.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /venv/main/lib/python3.10/site-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /venv/main/lib/python3.10/site-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (2025.1.31)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /venv/main/lib/python3.10/site-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /venv/main/lib/python3.10/site-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (3.10)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /venv/main/lib/python3.10/site-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /venv/main/lib/python3.10/site-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /venv/main/lib/python3.10/site-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (12.4.127)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /venv/main/lib/python3.10/site-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (4.12.2)\n",
      "Requirement already satisfied: triton==3.2.0 in /venv/main/lib/python3.10/site-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (3.2.0)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /venv/main/lib/python3.10/site-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /venv/main/lib/python3.10/site-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (10.3.5.147)\n",
      "Requirement already satisfied: filelock in /venv/main/lib/python3.10/site-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (3.17.0)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /venv/main/lib/python3.10/site-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /venv/main/lib/python3.10/site-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /venv/main/lib/python3.10/site-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /venv/main/lib/python3.10/site-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (0.6.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in /venv/main/lib/python3.10/site-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (1.13.1)\n",
      "Requirement already satisfied: jinja2 in /venv/main/lib/python3.10/site-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /venv/main/lib/python3.10/site-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (12.4.127)\n",
      "Requirement already satisfied: fsspec in /venv/main/lib/python3.10/site-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /venv/main/lib/python3.10/site-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (12.4.127)\n",
      "Requirement already satisfied: networkx in /venv/main/lib/python3.10/site-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (3.3)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /venv/main/lib/python3.10/site-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /venv/main/lib/python3.10/site-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (11.6.1.9)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /venv/main/lib/python3.10/site-packages (from sympy==1.13.1->torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (1.3.0)\n",
      "Collecting absl-py>=0.4\n",
      "  Downloading absl_py-2.2.2-py3-none-any.whl (135 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.6/135.6 KB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: setuptools>=41.0.0 in /venv/main/lib/python3.10/site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (59.6.0)\n",
      "Collecting grpcio>=1.48.2\n",
      "  Downloading grpcio-1.71.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m102.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m98.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 KB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.3/106.3 KB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six>1.9 in /venv/main/lib/python3.10/site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.17.0)\n",
      "Collecting tzdata>=2022.7\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m347.8/347.8 KB\u001b[0m \u001b[31m64.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting pytz>=2020.1\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m509.2/509.2 KB\u001b[0m \u001b[31m55.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Requirement already satisfied: matplotlib-inline in /venv/main/lib/python3.10/site-packages (from ipython->-r requirements.txt (line 34)) (0.1.7)\n",
      "Requirement already satisfied: decorator in /venv/main/lib/python3.10/site-packages (from ipython->-r requirements.txt (line 34)) (5.2.1)\n",
      "Requirement already satisfied: exceptiongroup in /venv/main/lib/python3.10/site-packages (from ipython->-r requirements.txt (line 34)) (1.2.2)\n",
      "Requirement already satisfied: jedi>=0.16 in /venv/main/lib/python3.10/site-packages (from ipython->-r requirements.txt (line 34)) (0.19.2)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in /venv/main/lib/python3.10/site-packages (from ipython->-r requirements.txt (line 34)) (5.14.3)\n",
      "Requirement already satisfied: pexpect>4.3 in /venv/main/lib/python3.10/site-packages (from ipython->-r requirements.txt (line 34)) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /venv/main/lib/python3.10/site-packages (from ipython->-r requirements.txt (line 34)) (3.0.50)\n",
      "Requirement already satisfied: stack_data in /venv/main/lib/python3.10/site-packages (from ipython->-r requirements.txt (line 34)) (0.6.3)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /venv/main/lib/python3.10/site-packages (from ipython->-r requirements.txt (line 34)) (2.19.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /venv/main/lib/python3.10/site-packages (from jedi>=0.16->ipython->-r requirements.txt (line 34)) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /venv/main/lib/python3.10/site-packages (from pexpect>4.3->ipython->-r requirements.txt (line 34)) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /venv/main/lib/python3.10/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython->-r requirements.txt (line 34)) (0.2.13)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /venv/main/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard>=2.4.1->-r requirements.txt (line 17)) (2.1.5)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /venv/main/lib/python3.10/site-packages (from stack_data->ipython->-r requirements.txt (line 34)) (3.0.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /venv/main/lib/python3.10/site-packages (from stack_data->ipython->-r requirements.txt (line 34)) (2.2.0)\n",
      "Requirement already satisfied: pure-eval in /venv/main/lib/python3.10/site-packages (from stack_data->ipython->-r requirements.txt (line 34)) (0.2.3)\n",
      "Installing collected packages: pytz, werkzeug, tzdata, tensorboard-data-server, pyparsing, protobuf, numpy, markdown, kiwisolver, grpcio, fonttools, cycler, absl-py, tensorboard, scipy, pandas, opencv-python, contourpy, matplotlib, thop, seaborn\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.1.2\n",
      "    Uninstalling numpy-2.1.2:\n",
      "      Successfully uninstalled numpy-2.1.2\n",
      "Successfully installed absl-py-2.2.2 contourpy-1.3.1 cycler-0.12.1 fonttools-4.57.0 grpcio-1.71.0 kiwisolver-1.4.8 markdown-3.7 matplotlib-3.10.1 numpy-1.23.5 opencv-python-4.11.0.86 pandas-2.2.3 protobuf-4.21.2 pyparsing-3.2.3 pytz-2025.2 scipy-1.15.2 seaborn-0.13.2 tensorboard-2.19.0 tensorboard-data-server-0.7.2 thop-0.1.1.post2209072238 tzdata-2025.2 werkzeug-3.1.3\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "358979fd-2281-40ef-b5ea-0e3facf32184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'yolov7'...\n",
      "remote: Enumerating objects: 1197, done.\u001b[K\n",
      "remote: Total 1197 (delta 0), reused 0 (delta 0), pack-reused 1197 (from 1)\u001b[K\n",
      "Receiving objects: 100% (1197/1197), 74.23 MiB | 16.23 MiB/s, done.\n",
      "Resolving deltas: 100% (520/520), done.\n"
     ]
    }
   ],
   "source": [
    "# Cloning the YOLOv7 repo\n",
    "!git clone https://github.com/WongKinYiu/yolov7.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8adb5ac-49b9-4869-9e50-c88f866046a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "annotations_dir = 'NEUDET/ANNOTATIONS'\n",
    "labels_dir = 'NEUDET/labels'\n",
    "images_dir = 'NEUDET/IMAGES'\n",
    "\n",
    "if not os.path.exists(labels_dir):\n",
    "    os.makedirs(labels_dir)\n",
    "\n",
    "class_names = ['crazing', 'inclusion', 'patches', 'pitted_surface', 'rolled_in_scale', 'scratches']\n",
    "class_map = {name: idx for idx, name in enumerate(class_names)}\n",
    "\n",
    "def convert_annotation(xml_file, img_width=200, img_height=200):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "    annotation_lines = []\n",
    "    for obj in root.findall('object'):\n",
    "        cls = obj.find('name').text.strip().lower()\n",
    "        if cls not in class_map:\n",
    "            continue  # skip unknown class\n",
    "        cls_id = class_map[cls]\n",
    "        xmlbox = obj.find('bndbox')\n",
    "        xmin = float(xmlbox.find('xmin').text)\n",
    "        ymin = float(xmlbox.find('ymin').text)\n",
    "        xmax = float(xmlbox.find('xmax').text)\n",
    "        ymax = float(xmlbox.find('ymax').text)\n",
    "\n",
    "        # Convert to YOLO format\n",
    "        x_center = ((xmin + xmax) / 2.0) / img_width\n",
    "        y_center = ((ymin + ymax) / 2.0) / img_height\n",
    "        width = (xmax - xmin) / img_width\n",
    "        height = (ymax - ymin) / img_height\n",
    "        annotation_lines.append(f\"{cls_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\")\n",
    "    return annotation_lines\n",
    "\n",
    "# Process each .xml in ANNOTATIONS\n",
    "for filename in os.listdir(annotations_dir):\n",
    "    if filename.endswith('.xml'):\n",
    "        xml_path = os.path.join(annotations_dir, filename)\n",
    "        yolo_lines = convert_annotation(xml_path)\n",
    "        base_name = os.path.splitext(filename)[0]\n",
    "        txt_path = os.path.join(labels_dir, base_name + '.txt')\n",
    "        with open(txt_path, 'w') as f:\n",
    "            f.write(\"\\n\".join(yolo_lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c78147d6-23ab-4d75-9290-0acbf02725c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INVALID] NEUDET/labels/crazing_120.txt => contains duplicate bounding boxes.\n",
      "Skipping corrupted label file: crazing_120.txt\n",
      "[INVALID] NEUDET/labels/inclusion_62.txt => contains duplicate bounding boxes.\n",
      "Skipping corrupted label file: inclusion_62.txt\n",
      "[INVALID] NEUDET/labels/patches_198.txt => contains duplicate bounding boxes.\n",
      "Skipping corrupted label file: patches_198.txt\n",
      "[INVALID] NEUDET/labels/crazing_120.txt => contains duplicate bounding boxes.\n",
      "Removed corrupted file: crazing_120.txt\n",
      "[INVALID] NEUDET/labels/inclusion_62.txt => contains duplicate bounding boxes.\n",
      "Removed corrupted file: inclusion_62.txt\n",
      "[INVALID] NEUDET/labels/patches_198.txt => contains duplicate bounding boxes.\n",
      "Removed corrupted file: patches_198.txt\n",
      "Valid label files: 1797\n"
     ]
    }
   ],
   "source": [
    "###################################\n",
    "# 5) Verify label files and remove corrupted\n",
    "###################################\n",
    "def is_valid_label_file(file_path):\n",
    "    \"\"\"\n",
    "    Check if a YOLO-format label file is valid.\n",
    "    A valid file has each non-empty line split into exactly 5 values\n",
    "    and no duplicate bounding boxes.\n",
    "    Empty files are allowed (no object).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r') as f:\n",
    "            lines = [line.strip() for line in f if line.strip()]\n",
    "        if not lines:\n",
    "            return True  # empty => OK\n",
    "        boxes = []\n",
    "        for line in lines:\n",
    "            parts = line.split()\n",
    "            if len(parts) != 5:\n",
    "                print(f\"[INVALID] {file_path} => line '{line}' does not have 5 values.\")\n",
    "                return False\n",
    "            try:\n",
    "                box = tuple(float(x) for x in parts)\n",
    "            except:\n",
    "                print(f\"[INVALID] {file_path} => cannot convert line '{line}' to float.\")\n",
    "                return False\n",
    "            boxes.append(box)\n",
    "        if len(boxes) != len(set(boxes)):\n",
    "            print(f\"[INVALID] {file_path} => contains duplicate bounding boxes.\")\n",
    "            return False\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] {file_path} => {e}\")\n",
    "        return False\n",
    "\n",
    "valid_label_files = []\n",
    "for filename in os.listdir(labels_dir):\n",
    "    if filename.endswith('.txt'):\n",
    "        file_path = os.path.join(labels_dir, filename)\n",
    "        if is_valid_label_file(file_path):\n",
    "            valid_label_files.append(filename)\n",
    "        else:\n",
    "            print(f\"Skipping corrupted label file: {filename}\")\n",
    "\n",
    "# Remove corrupted from disk\n",
    "for filename in os.listdir(labels_dir):\n",
    "    if filename.endswith('.txt'):\n",
    "        file_path = os.path.join(labels_dir, filename)\n",
    "        if not is_valid_label_file(file_path):\n",
    "            os.remove(file_path)\n",
    "            print(f\"Removed corrupted file: {filename}\")\n",
    "\n",
    "print(f\"Valid label files: {len(valid_label_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fb014f00-a5f3-4ff7-ac23-5d1ddf516740",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "# 6) Split into train/val/test\n",
    "###################################\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "output_base = './NEUDET_split'\n",
    "os.makedirs(output_base, exist_ok=True)\n",
    "for phase in ['train', 'val', 'test']:\n",
    "    os.makedirs(os.path.join(output_base, phase, 'images'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(output_base, phase, 'labels'), exist_ok=True)\n",
    "\n",
    "# Gather images\n",
    "image_files = [f for f in os.listdir(images_dir) if f.endswith('.jpg')]\n",
    "random.shuffle(image_files)\n",
    "\n",
    "n = len(image_files)\n",
    "train_split = int(0.8 * n)\n",
    "val_split = int(0.9 * n)\n",
    "\n",
    "train_files = image_files[:train_split]\n",
    "val_files = image_files[train_split:val_split]\n",
    "test_files = image_files[val_split:]\n",
    "\n",
    "def copy_files(file_list, phase):\n",
    "    for file in file_list:\n",
    "        # Copy image\n",
    "        shutil.copy(os.path.join(images_dir, file),\n",
    "                    os.path.join(output_base, phase, 'images', file))\n",
    "        # Copy label\n",
    "        label_file = os.path.splitext(file)[0] + '.txt'\n",
    "        src_label = os.path.join(labels_dir, label_file)\n",
    "        dst_label = os.path.join(output_base, phase, 'labels', label_file)\n",
    "        if os.path.exists(src_label):\n",
    "            shutil.copy(src_label, dst_label)\n",
    "\n",
    "copy_files(train_files, 'train')\n",
    "copy_files(val_files, 'val')\n",
    "copy_files(test_files, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4bb2cae4-00fa-4dcd-bac4-6f6ea1c9e3df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/yolov7\n"
     ]
    }
   ],
   "source": [
    "###################################\n",
    "# 7) Create the data/neu_det.yaml inside yolov7\n",
    "###################################\n",
    "%cd yolov7\n",
    "\n",
    "!mkdir -p data\n",
    "with open('data/neu_det.yaml', 'w') as f:\n",
    "    f.write(\"\"\"train: ../NEUDET_split/train/images\n",
    "val: ../NEUDET_split/val/images\n",
    "test: ../NEUDET_split/test/images\n",
    "\n",
    "nc: 6\n",
    "names: [crazing, inclusion, patches, pitted_surface, rolled_in_scale, scratches]\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6999d506-ac08-4ff0-be62-4cd95ba2ae00",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "# 8) Append custom modules to models/common.py\n",
    "###################################\n",
    "custom_code = r\"\"\"\n",
    "# ----- Custom Modules for SS-YOLO -----\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class DWConv(nn.Module):\n",
    "\n",
    "    def __init__(self, c1, c2, k=3, s=1):\n",
    "        super(DWConv, self).__init__()\n",
    "        self.dw = nn.Conv2d(c1, c1, k, s, k//2, groups=c1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(c1)\n",
    "        self.act1 = nn.ReLU(inplace=True)\n",
    "        self.pw = nn.Conv2d(c1, c2, 1, 1, 0, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(c2)\n",
    "    def forward(self, x):\n",
    "        x = self.act1(self.bn1(self.dw(x)))\n",
    "        x = self.bn2(self.pw(x))\n",
    "        return x\n",
    "\n",
    "class DSimSPPF(nn.Module):\n",
    "\n",
    "    def __init__(self, c1, c2, k=5):\n",
    "        super(DSimSPPF, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(c1, c1, 1, 1, 0, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(c1)\n",
    "        self.act1 = nn.ReLU(inplace=True)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=k, stride=1, padding=k//2)\n",
    "        self.conv2 = nn.Conv2d(c1*4, c1*4, 3, 1, 1, groups=c1*4, bias=False)\n",
    "        self.point = nn.Conv2d(c1*4, c2, 1, 1, 0, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(c2)\n",
    "        self.act2 = nn.ReLU(inplace=True)\n",
    "    def forward(self, x):\n",
    "        x = self.act1(self.bn1(self.conv1(x)))\n",
    "        y1 = self.pool(x)\n",
    "        y2 = self.pool(y1)\n",
    "        y3 = self.pool(y2)\n",
    "        y = torch.cat([x, y1, y2, y3], dim=1)\n",
    "        y = self.conv2(y)\n",
    "        y = self.act2(self.bn2(self.point(y)))\n",
    "        return y\n",
    "\n",
    "class SimAM_Module(nn.Module):\n",
    "\n",
    "    def __init__(self, lambda_val=0.1):\n",
    "        super(SimAM_Module, self).__init__()\n",
    "        self.lambda_val = lambda_val\n",
    "    def forward(self, x):\n",
    "        n, c, h, w = x.shape\n",
    "        x_mean = x.mean(dim=[2,3], keepdim=True)\n",
    "        d = (x - x_mean).pow(2)\n",
    "        var = d.sum(dim=[2,3], keepdim=True) / (h*w - 1 + 1e-6)\n",
    "        e_inv = d / (4 * (var + self.lambda_val)) + 0.5\n",
    "        return x * torch.sigmoid(e_inv)\n",
    "\"\"\"\n",
    "\n",
    "# Append to common.py\n",
    "with open('models/common.py', 'a') as f:\n",
    "    f.write('\\n' + custom_code + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6be9983f-6068-468a-b8e9-e5ef66fbbed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace\n"
     ]
    }
   ],
   "source": [
    "###################################\n",
    "# 9) Create ssyolo.yaml in cfg/training\n",
    "###################################\n",
    "!mkdir -p cfg/training\n",
    "ssyolo_code = r\"\"\"\n",
    "# SS-YOLO model configuration (MobileNetv3 backbone + SimAM + D-SimSPPF)\n",
    "nc: 6\n",
    "depth_multiple: 1.0\n",
    "width_multiple: 1.0\n",
    "\n",
    "# Usually, 3 anchors per scale\n",
    "anchors:\n",
    "  - [12,16, 19,36, 40,28]   # P3/8\n",
    "  - [36,75, 76,55, 72,146]  # P4/16\n",
    "  - [142,110, 192,243, 459,401]  # P5/32\n",
    "\n",
    "backbone:\n",
    "  [[-1, 1, Conv, [16, 3, 2]],          \n",
    "   [-1, 1, Conv, [16, 3, 1]],          \n",
    "   [[-2, -1], 1, Shortcut, [0]],       \n",
    "   [-1, 1, Conv, [64, 1, 1]],          \n",
    "   [-1, 1, DWConv, [24, 3, 2]],        \n",
    "   [-1, 1, Conv, [72, 1, 1]],          \n",
    "   [-1, 1, DWConv, [24, 3, 1]],        \n",
    "   [[4, -1], 1, Shortcut, [0]],        \n",
    "   [-1, 1, Conv, [72, 1, 1]],          \n",
    "   [-1, 1, DWConv, [40, 5, 2]],        \n",
    "   [-1, 1, Conv, [120, 1, 1]],         \n",
    "   [-1, 1, DWConv, [40, 5, 1]],        \n",
    "   [[9, -1], 1, Shortcut, [0]],        \n",
    "   [-1, 1, Conv, [120, 1, 1]],         \n",
    "   [-1, 1, DWConv, [40, 5, 1]],        \n",
    "   [[12, -1], 1, Shortcut, [0]],       \n",
    "   [-1, 1, Conv, [240, 1, 1]],         \n",
    "   [-1, 1, DWConv, [80, 3, 2]],        \n",
    "   [-1, 1, Conv, [200, 1, 1]],         \n",
    "   [-1, 1, DWConv, [80, 3, 1]],        \n",
    "   [[17, -1], 1, Shortcut, [0]],       \n",
    "   [-1, 1, Conv, [184, 1, 1]],         \n",
    "   [-1, 1, DWConv, [80, 3, 1]],        \n",
    "   [[20, -1], 1, Shortcut, [0]],       \n",
    "   [-1, 1, Conv, [184, 1, 1]],         \n",
    "   [-1, 1, DWConv, [80, 3, 1]],        \n",
    "   [[23, -1], 1, Shortcut, [0]],       \n",
    "   [-1, 1, Conv, [480, 1, 1]],         \n",
    "   [-1, 1, DWConv, [112, 3, 1]],       \n",
    "   [-1, 1, Conv, [672, 1, 1]],         \n",
    "   [-1, 1, DWConv, [112, 3, 1]],       \n",
    "   [[28, -1], 1, Shortcut, [0]],       \n",
    "   [-1, 1, Conv, [672, 1, 1]],         \n",
    "   [-1, 1, DWConv, [160, 5, 2]],       \n",
    "   [-1, 1, Conv, [960, 1, 1]],         \n",
    "   [-1, 1, DWConv, [160, 5, 1]],       \n",
    "   [[33, -1], 1, Shortcut, [0]],       \n",
    "   [-1, 1, Conv, [960, 1, 1]],         \n",
    "   [-1, 1, DWConv, [160, 5, 1]],       \n",
    "   [[36, -1], 1, Shortcut, [0]],       \n",
    "   [-1, 1, Conv, [960, 1, 1]]          \n",
    "  ]\n",
    "\n",
    "head:\n",
    "  [[40, 1, DSimSPPF, [960, 960, 5]],           \n",
    "   [41, 1, SimAM_Module, [0.1]],       \n",
    "   [42, 1, Conv, [256, 1, 1]],         \n",
    "   [43, 1, nn.Upsample, [None, 2, 'nearest']],  \n",
    "   [26, 1, Conv, [256, 1, 1]],         \n",
    "   [[45, 44], 1, Concat, [1]],         \n",
    "   [46, 1, Conv, [256, 1, 1]],         \n",
    "   [46, 1, Conv, [128, 3, 1]],         \n",
    "   [48, 1, Conv, [128, 3, 1]],         \n",
    "   [49, 1, Conv, [128, 1, 1]],         \n",
    "   [50, 1, nn.Upsample, [None, 2, 'nearest']],  \n",
    "   [15, 1, Conv, [128, 1, 1]],         \n",
    "   [[52, 51], 1, Concat, [1]],         \n",
    "   [53, 1, Conv, [128, 1, 1]],         \n",
    "   [53, 1, Conv, [64, 3, 1]],          \n",
    "   [55, 1, Conv, [64, 3, 1]],          \n",
    "   [56, 1, Conv, [64, 3, 1]],          \n",
    "   [57, 1, Conv, [64, 3, 1]],          \n",
    "   [58, 1, Conv, [128, 1, 1]],         \n",
    "   [59, 1, Conv, [128, 3, 2]],         \n",
    "   [[60, 50], 1, Concat, [1]],         \n",
    "   [61, 1, Conv, [256, 1, 1]],         \n",
    "   [62, 1, Conv, [128, 3, 1]],         \n",
    "   [63, 1, Conv, [128, 3, 1]],         \n",
    "   [64, 1, Conv, [256, 3, 2]],         \n",
    "   [[65, 43], 1, Concat, [1]],         \n",
    "   [66, 1, Conv, [256, 1, 1]],         \n",
    "   [67, 1, Conv, [128, 3, 1]],         \n",
    "   [68, 1, Conv, [128, 3, 1]],         \n",
    "   [69, 1, SimAM_Module, [0.1]],       \n",
    "   [[59, 64, 69], 1, IDetect, [nc, anchors]]\n",
    "  ]\n",
    "\"\"\"\n",
    "with open('cfg/training/ssyolo.yaml', 'w') as f:\n",
    "    f.write(ssyolo_code)\n",
    "\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d60c3ca8-1a60-4067-ba85-b208e82c7334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/yolov7\n",
      "Model(\n",
      "  (model): Sequential(\n",
      "    (0): Conv(\n",
      "      (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (1): Conv(\n",
      "      (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (2): Shortcut()\n",
      "    (3): Conv(\n",
      "      (conv): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (4): DWConv(\n",
      "      (dw): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (pw): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(24, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (5): Conv(\n",
      "      (conv): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (6): DWConv(\n",
      "      (dw): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
      "      (bn1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (pw): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(24, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (7): Shortcut()\n",
      "    (8): Conv(\n",
      "      (conv): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (9): DWConv(\n",
      "      (dw): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
      "      (bn1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (pw): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (10): Conv(\n",
      "      (conv): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (11): DWConv(\n",
      "      (dw): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "      (bn1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (pw): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (12): Shortcut()\n",
      "    (13): Conv(\n",
      "      (conv): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (14): DWConv(\n",
      "      (dw): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "      (bn1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (pw): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (15): Shortcut()\n",
      "    (16): Conv(\n",
      "      (conv): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(240, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (17): DWConv(\n",
      "      (dw): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
      "      (bn1): BatchNorm2d(240, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (pw): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (18): Conv(\n",
      "      (conv): Conv2d(80, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(200, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (19): DWConv(\n",
      "      (dw): Conv2d(200, 200, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=200, bias=False)\n",
      "      (bn1): BatchNorm2d(200, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (pw): Conv2d(200, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (20): Shortcut()\n",
      "    (21): Conv(\n",
      "      (conv): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (22): DWConv(\n",
      "      (dw): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
      "      (bn1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (pw): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (23): Shortcut()\n",
      "    (24): Conv(\n",
      "      (conv): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (25): DWConv(\n",
      "      (dw): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
      "      (bn1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (pw): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (26): Shortcut()\n",
      "    (27): Conv(\n",
      "      (conv): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (28): DWConv(\n",
      "      (dw): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "      (bn1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (pw): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (29): Conv(\n",
      "      (conv): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (30): DWConv(\n",
      "      (dw): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
      "      (bn1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (pw): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (31): Shortcut()\n",
      "    (32): Conv(\n",
      "      (conv): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (33): DWConv(\n",
      "      (dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
      "      (bn1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (pw): Conv2d(672, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (34): Conv(\n",
      "      (conv): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(960, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (35): DWConv(\n",
      "      (dw): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
      "      (bn1): BatchNorm2d(960, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (pw): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (36): Shortcut()\n",
      "    (37): Conv(\n",
      "      (conv): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(960, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (38): DWConv(\n",
      "      (dw): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
      "      (bn1): BatchNorm2d(960, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (pw): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (39): Shortcut()\n",
      "    (40): Conv(\n",
      "      (conv): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(960, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (41): DSimSPPF(\n",
      "      (conv1): Conv2d(960, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(960, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (pool): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
      "      (conv2): Conv2d(3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)\n",
      "      (point): Conv2d(3840, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(960, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act2): ReLU(inplace=True)\n",
      "    )\n",
      "    (42): SimAM_Module()\n",
      "    (43): Conv(\n",
      "      (conv): Conv2d(960, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (44): Upsample(scale_factor=2.0, mode='nearest')\n",
      "    (45): Conv(\n",
      "      (conv): Conv2d(80, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (46): Concat()\n",
      "    (47): Conv(\n",
      "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (48): Conv(\n",
      "      (conv): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (49): Conv(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (50): Conv(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (51): Upsample(scale_factor=2.0, mode='nearest')\n",
      "    (52): Conv(\n",
      "      (conv): Conv2d(40, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (53): Concat()\n",
      "    (54): Conv(\n",
      "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (55): Conv(\n",
      "      (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (56): Conv(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (57): Conv(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (58): Conv(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (59): Conv(\n",
      "      (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (60): Conv(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (61): Concat()\n",
      "    (62): Conv(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (63): Conv(\n",
      "      (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (64): Conv(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (65): Conv(\n",
      "      (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (66): Concat()\n",
      "    (67): Conv(\n",
      "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (68): Conv(\n",
      "      (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (69): Conv(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (70): SimAM_Module()\n",
      "    (71): IDetect(\n",
      "      (m): ModuleList(\n",
      "        (0-2): 3 x Conv2d(128, 33, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (ia): ModuleList(\n",
      "        (0-2): 3 x ImplicitA()\n",
      "      )\n",
      "      (im): ModuleList(\n",
      "        (0-2): 3 x ImplicitM()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "/workspace\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/venv/main/lib/python3.10/site-packages/torch/functional.py:539: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /pytorch/aten/src/ATen/native/TensorShape.cpp:3637.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "/venv/main/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "###################################\n",
    "# 10) Verify model architecture\n",
    "###################################\n",
    "%cd yolov7\n",
    "from models.yolo import Model\n",
    "\n",
    "# IMPORTANT: Use ch=3 for RGB, since the paper uses 3-channel input\n",
    "model = Model(\"cfg/training/ssyolo.yaml\", ch=3, nc=6)\n",
    "print(model)\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89575ee2-233e-4e45-9046-b08f229bbff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/yolov7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/venv/main/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "cd yolov7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "903f5ffa-0437-4e79-8574-6b84cf2e0a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(weights=['runs/train/ssyolo_scratch_neu/weights/best.pt'], data='data/neu_det.yaml', batch_size=32, img_size=640, conf_thres=0.001, iou_thres=0.65, task='test', device='', single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project='runs/test', name='exp', exist_ok=False, no_trace=False, v5_metric=False)\n",
      "YOLOR 🚀 v0.1-128-ga207844 torch 2.6.0+cu124 CUDA:0 (NVIDIA GeForce RTX 4090, 24107.0625MB)\n",
      "\n",
      "Fusing layers... \n",
      "IDetect.fuse\n",
      "/venv/main/lib/python3.10/site-packages/torch/functional.py:539: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /pytorch/aten/src/ATen/native/TensorShape.cpp:3637.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "Model Summary: 240 layers, 9097222 parameters, 0 gradients, 17.5 GFLOPS\n",
      " Convert model to Traced-model... \n",
      " traced_script_module saved! \n",
      " model is traced! \n",
      "\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning '../NEUDET_split/test/labels' images and labels... 180 found, 0 m\u001b[0m\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mNew cache created: ../NEUDET_split/test/labels.cache\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all         180         334       0.758       0.799       0.827       0.451\n",
      "             crazing         180          73       0.599       0.369       0.445       0.132\n",
      "           inclusion         180          94       0.622       0.904       0.861       0.446\n",
      "             patches         180          74       0.758       0.946       0.959       0.597\n",
      "      pitted_surface         180          33       0.935       0.875       0.914       0.554\n",
      "           scratches         180          60       0.876         0.9       0.956       0.528\n",
      "Speed: 4.1/3.0/7.1 ms inference/NMS/total per 640x640 image at batch-size 32\n",
      "Results saved to runs/test/exp3\n"
     ]
    }
   ],
   "source": [
    "!python test.py \\\n",
    "  --weights runs/train/ssyolo_scratch_neu/weights/best.pt \\\n",
    "  --data data/neu_det.yaml \\\n",
    "  --img 640 \\\n",
    "  --task test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c50484b-9678-430b-bcc4-9af419a0a361",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
